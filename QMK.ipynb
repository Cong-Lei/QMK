{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f26a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import pymrmr\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747150c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100    # Size of the train dataset\n",
    "n_test = 60     # Size of the test dataset\n",
    "n_dim = 8       # 需要降到多少维\n",
    "target_label_list = [0,1,2] #需要提取数据的标签列表\n",
    "run_numbers = 1           #重复运行多少次,每次随机设置gate-encoding 线路      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c940768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"QNN/data/\" # Data saving folder\n",
    "PREPROCESS = True          # If False, skip processing and load data from SAVE_PATH\n",
    "select_samples_with_labels = True       # 是否挑选特定标签的数据\n",
    "FS_state = True              # 是否进行图像特征提取\n",
    "fs_type = 'mRMR'               #图像特征提取的方式,'random','mRMR'\n",
    "load_selected_index = False   # 是否加载随机选择或者mRMR特征的索引\n",
    "mnist_dataset = keras.datasets.mnist  \n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "769da43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#做2分类两种方案，抽取0和1作为数据集，\n",
    "def extract_data_with_label(origin_data, origin_label, target_label_list):\n",
    "    new_data = []\n",
    "    new_labels = []\n",
    "    for i in range(len(origin_label)):\n",
    "        for j in range(len(target_label_list)):\n",
    "            if(origin_label[i] == target_label_list[j]):\n",
    "                new_data.append(origin_data[i,:,:])\n",
    "                new_labels.append(origin_label[i])\n",
    "    new_data = np.array(new_data)\n",
    "    new_labels = np.array(new_labels)\n",
    "    return new_data, new_labels\n",
    "\n",
    "if select_samples_with_labels == True:\n",
    "    test_images, test_labels = extract_data_with_label(test_images, test_labels, target_label_list)\n",
    "    train_images, train_labels = extract_data_with_label(train_images, train_labels, target_label_list)  \n",
    "\n",
    "# Reduce dataset size\n",
    "train_images = train_images[:n_train]\n",
    "train_labels = train_labels[:n_train]\n",
    "test_images = test_images[:n_test]\n",
    "test_labels = test_labels[:n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ebc4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_selected_list(selected_feature_num): #生成随机列表，用于选择特定的像素\n",
    "    selected_index_list = []\n",
    "    pixel_num = np.shape(test_images)[1] * np.shape(test_images)[2]\n",
    "    \n",
    "    if load_random_index == True:\n",
    "        selected_index_list = np.load(SAVE_PATH + \"selected_index_list_\" + str(random_selected_feature_num) + \"_01.npy\")\n",
    "        selected_index_list = selected_index_list.tolist()\n",
    "    else: \n",
    "        for i in range(selected_feature_num):\n",
    "            selected_index_list.append(random.randint(0,pixel_num-1))\n",
    "\n",
    "        selected_index_list = np.array(selected_index_list, requires_grad=False)\n",
    "        np.save(SAVE_PATH + \"selected_index_list_\" + str(random_selected_feature_num) + \"_01.npy\", selected_index_list)\n",
    "\n",
    "    return selected_index_list\n",
    "\n",
    "def get_mRMR_selected_list_with_train_data(orgin_imgs, labels, n_dim):\n",
    "    selected_index_list = []\n",
    "\n",
    "    if load_selected_index == True:\n",
    "        selected_index_list = np.load(SAVE_PATH + \"mRMR_selected_index_list_\" + str(n_dim) + \"_01.npy\")\n",
    "    else:\n",
    "        labels = np.reshape(labels, (np.shape(labels)[0], -1))\n",
    "        #mRMR应该是对训练集提取特征子集，然后在测试集上选取一样的特征子集来测试效果\n",
    "        orgin_imgs = np.reshape(orgin_imgs,(np.shape(orgin_imgs)[0],-1))\n",
    "        data = np.concatenate((labels,orgin_imgs), axis=1)\n",
    "\n",
    "        row_index_list = []\n",
    "        row_name = []\n",
    "        for i in range(len(labels)):\n",
    "            row_name = 'Row_' + str(i+1)\n",
    "            row_index_list.append(row_name)\n",
    "\n",
    "        column_index_list = []\n",
    "        column_name = []\n",
    "\n",
    "        for i in range(np.shape(orgin_imgs)[1] + 1):\n",
    "            column_name = 'Colum_' + str(i+1)\n",
    "            column_index_list.append(column_name)\n",
    "\n",
    "        data_df = pd.DataFrame(data, index=row_index_list, columns = column_index_list)\n",
    "        selected_index_list = pymrmr.mRMR(data_df, 'MID', n_dim)\n",
    "        np.save(SAVE_PATH + \"mRMR_selected_index_list_\" + str(n_dim) + \"_01.npy\", selected_index_list)\n",
    "    return selected_index_list\n",
    "\n",
    "def fs_with_random(ori_imgs, selected_index_list): # 随机选择若干个像素\n",
    "    new_images = []\n",
    "    selected_index_list.sort()\n",
    "    ori_imgs = np.reshape(ori_imgs,(np.shape(ori_imgs)[0],-1))\n",
    "\n",
    "    for i in range(len(selected_index_list)):\n",
    "        new_images.append(ori_imgs[:,selected_index_list[i]])\n",
    "\n",
    "    new_images = np.array(new_images, requires_grad=False)\n",
    "    new_images = np.transpose(new_images)\n",
    "    print('dim:',np.shape(new_images))\n",
    "    return new_images \n",
    "\n",
    "def fs_with_mRMR(ori_imgs, labels, selected_index_list):\n",
    "    #mRMR应该是对训练集提取特征子集，然后在测试集上选取一样的特征子集来测试效果\n",
    "    labels = np.reshape(labels, (np.shape(labels)[0], -1))\n",
    "    ori_imgs = np.reshape(ori_imgs,(np.shape(ori_imgs)[0],-1))\n",
    "    data = np.concatenate((labels,ori_imgs), axis=1)\n",
    "\n",
    "    row_index_list = []\n",
    "    row_name = []\n",
    "    for i in range(len(labels)):\n",
    "        row_name = 'Row_' + str(i+1)\n",
    "        row_index_list.append(row_name)\n",
    "\n",
    "    column_index_list = []\n",
    "    column_name = []\n",
    "\n",
    "    for i in range(np.shape(ori_imgs)[1] + 1):\n",
    "        column_name = 'Colum_' + str(i+1)\n",
    "        column_index_list.append(column_name)\n",
    "\n",
    "    data_df = pd.DataFrame(data, index=row_index_list, columns = column_index_list)\n",
    "    new_images = data_df[selected_index_list]\n",
    "    return np.array(new_images, dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb9ec9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(images, labels, fs_type, selected_index_list):\n",
    "    processed_images = []\n",
    "    if fs_type == 'random':\n",
    "        #random_index_list = get_random_selected_list(n_dim)\n",
    "        processed_images = fs_with_random(images, selected_index_list)\n",
    "    elif fs_type == 'mRMR':\n",
    "        #mRMR_index_list = get_mRMR_selected_list_with_train_data(train_images, train_labels, n_dim)\n",
    "        processed_images = fs_with_mRMR(images, labels, selected_index_list)\n",
    "\n",
    "    return processed_images \n",
    "\n",
    "if FS_state == True:\n",
    "    selected_index_list = []\n",
    "    if fs_type == 'mRMR':\n",
    "        selected_index_list = get_mRMR_selected_list_with_train_data(train_images, train_labels, n_dim)\n",
    "    elif fs_type == 'random':\n",
    "        selected_index_list = get_random_selected_list(n_dim)\n",
    "\n",
    "    test_images = feature_selection(test_images, test_labels, fs_type, selected_index_list)\n",
    "    train_images = feature_selection(train_images, train_labels, fs_type, selected_index_list)\n",
    "\n",
    "\n",
    "# Normalize pixel values within 0 and 1\n",
    "train_images = train_images / (np.max(train_images) - np.min(train_images))\n",
    "test_images = test_images / (np.max(test_images) - np.min(test_images))\n",
    "\n",
    "#当维数特别低时候，比如少于20维时，有些数据就全为0，需要剔除,label要同步处理\n",
    "train_remove_index = train_images.sum(axis=1)!=0\n",
    "test_remove_index = test_images.sum(axis=1)!=0\n",
    "\n",
    "train_images = train_images[train_remove_index,:]\n",
    "test_images = test_images[test_remove_index,:]\n",
    "\n",
    "#process labels\n",
    "train_labels = np.reshape(train_labels, (np.shape(train_labels)[0], -1))\n",
    "test_labels = np.reshape(test_labels, (np.shape(test_labels)[0], -1))\n",
    "\n",
    "train_labels = train_labels[train_remove_index,:]\n",
    "test_labels = test_labels[test_remove_index,:]\n",
    "\n",
    "train_labels = train_labels.reshape(-1)\n",
    "test_labels = test_labels.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3b69c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-processing of train images:\n",
      "1/100        \r",
      "2/100        \r",
      "3/100        \r",
      "4/100        \r",
      "5/100        \r",
      "6/100        \r",
      "7/100        \r",
      "8/100        \r",
      "9/100        \r",
      "10/100        \r",
      "11/100        \r",
      "12/100        \r",
      "13/100        \r",
      "14/100        \r",
      "15/100        \r",
      "16/100        \r",
      "17/100        \r",
      "18/100        \r",
      "19/100        \r",
      "20/100        \r",
      "21/100        \r",
      "22/100        \r",
      "23/100        \r",
      "24/100        \r",
      "25/100        \r",
      "26/100        \r",
      "27/100        \r",
      "28/100        \r",
      "29/100        \r",
      "30/100        \r",
      "31/100        \r",
      "32/100        \r",
      "33/100        \r",
      "34/100        \r",
      "35/100        \r",
      "36/100        \r",
      "37/100        \r",
      "38/100        \r",
      "39/100        \r",
      "40/100        \r",
      "41/100        \r",
      "42/100        \r",
      "43/100        \r",
      "44/100        \r",
      "45/100        \r",
      "46/100        \r",
      "47/100        \r",
      "48/100        \r",
      "49/100        \r",
      "50/100        \r",
      "51/100        \r",
      "52/100        \r",
      "53/100        \r",
      "54/100        \r",
      "55/100        \r",
      "56/100        \r",
      "57/100        \r",
      "58/100        \r",
      "59/100        \r",
      "60/100        \r",
      "61/100        \r",
      "62/100        \r",
      "63/100        \r",
      "64/100        \r",
      "65/100        \r",
      "66/100        \r",
      "67/100        \r",
      "68/100        \r",
      "69/100        \r",
      "70/100        \r",
      "71/100        \r",
      "72/100        \r",
      "73/100        \r",
      "74/100        \r",
      "75/100        \r",
      "76/100        \r",
      "77/100        \r",
      "78/100        \r",
      "79/100        \r",
      "80/100        \r",
      "81/100        \r",
      "82/100        \r",
      "83/100        \r",
      "84/100        \r",
      "85/100        \r",
      "86/100        \r",
      "87/100        \r",
      "88/100        \r",
      "89/100        \r",
      "90/100        \r",
      "91/100        \r",
      "92/100        \r",
      "93/100        \r",
      "94/100        \r",
      "95/100        \r",
      "96/100        \r",
      "97/100        \r",
      "98/100        \r",
      "99/100        \r",
      "100/100        \r\n",
      "pre-processing of test images:\n",
      "1/58        \r",
      "2/58        \r",
      "3/58        \r",
      "4/58        \r",
      "5/58        \r",
      "6/58        \r",
      "7/58        \r",
      "8/58        \r",
      "9/58        \r",
      "10/58        \r",
      "11/58        \r",
      "12/58        \r",
      "13/58        \r",
      "14/58        \r",
      "15/58        \r",
      "16/58        \r",
      "17/58        \r",
      "18/58        \r",
      "19/58        \r",
      "20/58        \r",
      "21/58        \r",
      "22/58        \r",
      "23/58        \r",
      "24/58        \r",
      "25/58        \r",
      "26/58        \r",
      "27/58        \r",
      "28/58        \r",
      "29/58        \r",
      "30/58        \r",
      "31/58        \r",
      "32/58        \r",
      "33/58        \r",
      "34/58        \r",
      "35/58        \r",
      "36/58        \r",
      "37/58        \r",
      "38/58        \r",
      "39/58        \r",
      "40/58        \r",
      "41/58        \r",
      "42/58        \r",
      "43/58        \r",
      "44/58        \r",
      "45/58        \r",
      "46/58        \r",
      "47/58        \r",
      "48/58        \r",
      "49/58        \r",
      "50/58        \r",
      "51/58        \r",
      "52/58        \r",
      "53/58        \r",
      "54/58        \r",
      "55/58        \r",
      "56/58        \r",
      "57/58        \r",
      "58/58        \r"
     ]
    }
   ],
   "source": [
    "def process_img_to_features(image):\n",
    "    img = image.flatten()\n",
    "    return img\n",
    "\n",
    "if PREPROCESS == True: #将图像数据拉成1维\n",
    "    new_train_images = []\n",
    "    print(\"pre-processing of train images:\")\n",
    "    for idx, img in enumerate(train_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, np.shape(train_images)[0]), end=\"\\r\")\n",
    "        new_train_images.append(process_img_to_features(img))\n",
    "      \n",
    "    train_images = np.array(new_train_images, requires_grad=False)\n",
    "\n",
    "    new_test_images = []\n",
    "    print(\"\\npre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, np.shape(test_images)[0]), end=\"\\r\")\n",
    "        new_test_images.append(process_img_to_features(img))\n",
    "   \n",
    "    test_images = np.array(new_test_images, requires_grad=False)\n",
    "\n",
    "    # Save pre-processed images\n",
    "    np.save(SAVE_PATH + \"new_train_images_\" + str(n_dim) + fs_type + \"_01.npy\", train_images)\n",
    "    np.save(SAVE_PATH + \"new_test_images_\" + str(n_dim) + fs_type + \"_01.npy\", test_images)\n",
    "\n",
    "\n",
    "# Load pre-processed images\n",
    "train_images = np.load(SAVE_PATH + \"new_train_images_\" + str(n_dim) + fs_type + \"_01.npy\")\n",
    "test_images = np.load(SAVE_PATH + \"new_test_images_\" + str(n_dim) + fs_type + \"_01.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e6c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the inputs is important since the embedding we use is periodic\n",
    "X_train_scaler = StandardScaler().fit(train_images)\n",
    "train_images = X_train_scaler.transform(train_images)\n",
    "\n",
    "X_test_scaler = StandardScaler().fit(test_images)\n",
    "test_images = X_test_scaler.transform(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f329d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = n_dim\n",
    "\n",
    "dev_kernel = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "\n",
    "projector = np.zeros((2**n_qubits, 2**n_qubits))\n",
    "projector[0, 0] = 1\n",
    "\n",
    "#随机生成100种路线，8根线路，RX，RY，RY就有3**8，乘以 H门有2**8 乘以CNOT门有2**8，一共有429981696\n",
    "#用列表代表线路门的排列：一共3层，第一层0代表RX门，1代表RY门，2代表RZ门；第二层1代表使用H门，0代表不使用，第三层0代表不用CNOT门，1代表设置CNOT门，\n",
    "#且与下一个qubit链接，比如目前在第1个qubit，则CNOT门是链接第1和第2qubit。\n",
    "def generate_circuit_code(wires):\n",
    "    circuit_code = []\n",
    "    for i in range(3):\n",
    "        for j in range(wires):\n",
    "            if(i == 0):\n",
    "                circuit_code.append(random.randint(0,2))\n",
    "            else:\n",
    "                circuit_code.append(random.randint(0,1))\n",
    "\n",
    "    return circuit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(x, wires, curcuit_code):\n",
    "    \"\"\"Building block of the embedding ansatz\"\"\"\n",
    "    for j, wire in enumerate(wires):\n",
    "        for i in range(np.shape(curcuit_code)[1]):\n",
    "            if i == 0:\n",
    "                if(curcuit_code[j,i] == 0):\n",
    "                    qml.RX(x[j], wires=[wire])\n",
    "                elif(curcuit_code[j,i] == 1):\n",
    "                    qml.RY(x[j], wires=[wire])\n",
    "                elif(curcuit_code[j,i] == 2):\n",
    "                    qml.RZ(x[j], wires=[wire])\n",
    "            elif i == 1:\n",
    "                if(curcuit_code[j,i] == 1):\n",
    "                    qml.Hadamard(wires=[wire])\n",
    "            elif i == 2:\n",
    "                if(curcuit_code[j,i] == 1):\n",
    "                    if j == len(wires) - 1:\n",
    "                        qml.CNOT(wires = [j, 0])\n",
    "                    else:\n",
    "                        qml.CNOT(wires = [j, j+1])\n",
    "       \n",
    "\n",
    "def ansatz(x, curcuit_code, wires):\n",
    "    \"\"\"The embedding ansatz\"\"\"\n",
    "    layer(x, wires, curcuit_code)\n",
    "\n",
    "\n",
    "adjoint_ansatz = qml.adjoint(ansatz)\n",
    "\n",
    "@qml.qnode(dev_kernel)\n",
    "def kernel_circuit(x1, x2, curcuit_code):\n",
    "    \"\"\"The quantum kernel.\"\"\"\n",
    "    ansatz(x1, curcuit_code, wires=range(n_qubits))\n",
    "    adjoint_ansatz(x2, curcuit_code, wires=range(n_qubits))\n",
    "    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))\n",
    "\n",
    "def multiple_kernel(x1,x2, curcuit_code_list):\n",
    "    value_list = []\n",
    "    for i in range(len(curcuit_code_list)):\n",
    "        value_list.append(kernel_circuit(x1,x2, curcuit_code_list[i]))\n",
    "    value = 0.4 * value_list[0] + 0.1 * value_list[1] + 0.25 * value_list[2] + 0.25 * value_list[3]\n",
    "    #return np.mean(value_list)\n",
    "    return value\n",
    "\n",
    "def kernel_matrix(A, B, curcuit_code):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[kernel_circuit(a, b, curcuit_code) for b in B] for a in A])\n",
    "\n",
    "index_list = [7,12,19,28]\n",
    "kernel_function_list = []\n",
    "curcuit_code_list =  np.loadtxt(\"circuit_code_cls3_mRMR_2.txt\", dtype='int')\n",
    "curcuit_code_opt_list = []\n",
    "\n",
    "for i in range(len(index_list)):\n",
    "    curcuit_code = curcuit_code_list[index_list[i]]\n",
    "    curcuit_code = np.reshape(curcuit_code, (n_dim,3), order='F')\n",
    "    curcuit_code_opt_list.append(curcuit_code)\n",
    "\n",
    "def multiple_kernel_matrix(A, B, curcuit_code_list):\n",
    "    \"\"\"Compute the matrix whose entries are the kernel\n",
    "       evaluated on pairwise data from sets A and B.\"\"\"\n",
    "    return np.array([[multiple_kernel(a, b, curcuit_code_list) for b in B] for a in A])\n",
    "\n",
    "\n",
    "accuracy_list = []\n",
    "for i in range(run_numbers):\n",
    "    #print(multiple_kernel_matrix(train_images[0], train_images[0], curcuit_code_opt_list))\n",
    "    kernel_function = lambda A, B: multiple_kernel_matrix(A, B, curcuit_code_opt_list)\n",
    "    svm = SVC(kernel=kernel_function, decision_function_shape = 'ovr').fit(train_images, train_labels)\n",
    "    predictions = svm.predict(test_images)\n",
    "\n",
    "    print(predictions)\n",
    "    print(test_labels)\n",
    "\n",
    "    accuracy_test = accuracy_score(predictions, test_labels)\n",
    "    print(f\"The accuracy of a kernel is {accuracy_test:.3f}\")\n",
    "    accuracy_list.append(accuracy_test)\n",
    "\n",
    "\n",
    "\n",
    "np.savetxt(\"circuit_code_cls3_\" + fs_type + \"0830.txt\", curcuit_code_list, fmt = '%d')\n",
    "np.savetxt(\"accuracy_test_cls3_\" + fs_type + \"0830.txt\", accuracy_list, fmt = '%s')\n",
    "\n",
    "print('max accuracy is :', max(accuracy_list))\n",
    "print('min accuracy is :', min(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682d11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
